{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ANNbuilder import build_network\n",
    "from pso_gridsearchcv import optimize\n",
    "from loss import mse_loss, cross_entropy\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from activation import logistic, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"banknote_authentication.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4], dtype='int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(4, axis=1).values\n",
    "y = data[4].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.6216 ,  8.6661 , -2.8073 , -0.44699],\n",
       "       [ 4.5459 ,  8.1674 , -2.4586 , -1.4621 ],\n",
       "       [ 3.866  , -2.6383 ,  1.9242 ,  0.10645],\n",
       "       [ 3.4566 ,  9.5228 , -4.0112 , -3.5944 ],\n",
       "       [ 0.32924, -4.4552 ,  4.5718 , -0.9888 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data separation and scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2398\n",
      "Epoch 200/500 - Loss: 0.2398\n",
      "Epoch 300/500 - Loss: 0.2398\n",
      "Epoch 400/500 - Loss: 0.2398\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2922\n",
      "Epoch 200/500 - Loss: 0.2922\n",
      "Epoch 300/500 - Loss: 0.2922\n",
      "Epoch 400/500 - Loss: 0.2922\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2590\n",
      "Epoch 200/500 - Loss: 0.2590\n",
      "Epoch 300/500 - Loss: 0.2590\n",
      "Epoch 400/500 - Loss: 0.2590\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1978\n",
      "Epoch 200/500 - Loss: 0.1978\n",
      "Epoch 300/500 - Loss: 0.1978\n",
      "Epoch 400/500 - Loss: 0.1978\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2547\n",
      "Epoch 200/500 - Loss: 0.2547\n",
      "Epoch 300/500 - Loss: 0.2547\n",
      "Epoch 400/500 - Loss: 0.2547\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2051\n",
      "Epoch 200/500 - Loss: 0.2051\n",
      "Epoch 300/500 - Loss: 0.2051\n",
      "Epoch 400/500 - Loss: 0.2051\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1851\n",
      "Epoch 200/500 - Loss: 0.1851\n",
      "Epoch 300/500 - Loss: 0.1851\n",
      "Epoch 400/500 - Loss: 0.1851\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2317\n",
      "Epoch 200/500 - Loss: 0.2317\n",
      "Epoch 300/500 - Loss: 0.2317\n",
      "Epoch 400/500 - Loss: 0.2317\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1943\n",
      "Epoch 200/500 - Loss: 0.1943\n",
      "Epoch 300/500 - Loss: 0.1943\n",
      "Epoch 400/500 - Loss: 0.1943\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2286\n",
      "Epoch 200/500 - Loss: 0.2286\n",
      "Epoch 300/500 - Loss: 0.2286\n",
      "Epoch 400/500 - Loss: 0.2286\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2034\n",
      "Epoch 200/500 - Loss: 0.2034\n",
      "Epoch 300/500 - Loss: 0.2034\n",
      "Epoch 400/500 - Loss: 0.2034\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2512\n",
      "Epoch 200/500 - Loss: 0.2512\n",
      "Epoch 300/500 - Loss: 0.2512\n",
      "Epoch 400/500 - Loss: 0.2512\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2512\n",
      "Epoch 200/500 - Loss: 0.2512\n",
      "Epoch 300/500 - Loss: 0.2512\n",
      "Epoch 400/500 - Loss: 0.2512\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2070\n",
      "Epoch 200/500 - Loss: 0.2070\n",
      "Epoch 300/500 - Loss: 0.2070\n",
      "Epoch 400/500 - Loss: 0.2070\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2484\n",
      "Epoch 200/500 - Loss: 0.2484\n",
      "Epoch 300/500 - Loss: 0.2484\n",
      "Epoch 400/500 - Loss: 0.2484\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2748\n",
      "Epoch 200/500 - Loss: 0.2748\n",
      "Epoch 300/500 - Loss: 0.2748\n",
      "Epoch 400/500 - Loss: 0.2748\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2228\n",
      "Epoch 200/500 - Loss: 0.2228\n",
      "Epoch 300/500 - Loss: 0.2228\n",
      "Epoch 400/500 - Loss: 0.2228\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2424\n",
      "Epoch 200/500 - Loss: 0.2424\n",
      "Epoch 300/500 - Loss: 0.2424\n",
      "Epoch 400/500 - Loss: 0.2424\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2939\n",
      "Epoch 200/500 - Loss: 0.2939\n",
      "Epoch 300/500 - Loss: 0.2939\n",
      "Epoch 400/500 - Loss: 0.2939\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2427\n",
      "Epoch 200/500 - Loss: 0.2427\n",
      "Epoch 300/500 - Loss: 0.2427\n",
      "Epoch 400/500 - Loss: 0.2427\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2334\n",
      "Epoch 200/500 - Loss: 0.2334\n",
      "Epoch 300/500 - Loss: 0.2334\n",
      "Epoch 400/500 - Loss: 0.2334\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2615\n",
      "Epoch 200/500 - Loss: 0.2615\n",
      "Epoch 300/500 - Loss: 0.2615\n",
      "Epoch 400/500 - Loss: 0.2615\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2351\n",
      "Epoch 200/500 - Loss: 0.2351\n",
      "Epoch 300/500 - Loss: 0.2351\n",
      "Epoch 400/500 - Loss: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2398\n",
      "Epoch 200/500 - Loss: 0.2398\n",
      "Epoch 300/500 - Loss: 0.2398\n",
      "Epoch 400/500 - Loss: 0.2398\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2922\n",
      "Epoch 200/500 - Loss: 0.2922\n",
      "Epoch 300/500 - Loss: 0.2922\n",
      "Epoch 400/500 - Loss: 0.2922\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2590\n",
      "Epoch 200/500 - Loss: 0.2590\n",
      "Epoch 300/500 - Loss: 0.2590\n",
      "Epoch 400/500 - Loss: 0.2590\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1978\n",
      "Epoch 200/500 - Loss: 0.1978\n",
      "Epoch 300/500 - Loss: 0.1978\n",
      "Epoch 400/500 - Loss: 0.1978\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2547\n",
      "Epoch 200/500 - Loss: 0.2547\n",
      "Epoch 300/500 - Loss: 0.2547\n",
      "Epoch 400/500 - Loss: 0.2547\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2051\n",
      "Epoch 200/500 - Loss: 0.2051\n",
      "Epoch 300/500 - Loss: 0.2051\n",
      "Epoch 400/500 - Loss: 0.2051\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1851\n",
      "Epoch 200/500 - Loss: 0.1851\n",
      "Epoch 300/500 - Loss: 0.1851\n",
      "Epoch 400/500 - Loss: 0.1851\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2317\n",
      "Epoch 200/500 - Loss: 0.2317\n",
      "Epoch 300/500 - Loss: 0.2317\n",
      "Epoch 400/500 - Loss: 0.2317\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1943\n",
      "Epoch 200/500 - Loss: 0.1943\n",
      "Epoch 300/500 - Loss: 0.1943\n",
      "Epoch 400/500 - Loss: 0.1943\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2286\n",
      "Epoch 200/500 - Loss: 0.2286\n",
      "Epoch 300/500 - Loss: 0.2286\n",
      "Epoch 400/500 - Loss: 0.2286\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2034\n",
      "Epoch 200/500 - Loss: 0.2034\n",
      "Epoch 300/500 - Loss: 0.2034\n",
      "Epoch 400/500 - Loss: 0.2034\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2512\n",
      "Epoch 200/500 - Loss: 0.2512\n",
      "Epoch 300/500 - Loss: 0.2512\n",
      "Epoch 400/500 - Loss: 0.2512\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2512\n",
      "Epoch 200/500 - Loss: 0.2512\n",
      "Epoch 300/500 - Loss: 0.2512\n",
      "Epoch 400/500 - Loss: 0.2512\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2070\n",
      "Epoch 200/500 - Loss: 0.2070\n",
      "Epoch 300/500 - Loss: 0.2070\n",
      "Epoch 400/500 - Loss: 0.2070\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2484\n",
      "Epoch 200/500 - Loss: 0.2484\n",
      "Epoch 300/500 - Loss: 0.2484\n",
      "Epoch 400/500 - Loss: 0.2484\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2748\n",
      "Epoch 200/500 - Loss: 0.2748\n",
      "Epoch 300/500 - Loss: 0.2748\n",
      "Epoch 400/500 - Loss: 0.2748\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2228\n",
      "Epoch 200/500 - Loss: 0.2228\n",
      "Epoch 300/500 - Loss: 0.2228\n",
      "Epoch 400/500 - Loss: 0.2228\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2424\n",
      "Epoch 200/500 - Loss: 0.2424\n",
      "Epoch 300/500 - Loss: 0.2424\n",
      "Epoch 400/500 - Loss: 0.2424\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2939\n",
      "Epoch 200/500 - Loss: 0.2939\n",
      "Epoch 300/500 - Loss: 0.2939\n",
      "Epoch 400/500 - Loss: 0.2939\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2427\n",
      "Epoch 200/500 - Loss: 0.2427\n",
      "Epoch 300/500 - Loss: 0.2427\n",
      "Epoch 400/500 - Loss: 0.2427\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2334\n",
      "Epoch 200/500 - Loss: 0.2334\n",
      "Epoch 300/500 - Loss: 0.2334\n",
      "Epoch 400/500 - Loss: 0.2334\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2615\n",
      "Epoch 200/500 - Loss: 0.2615\n",
      "Epoch 300/500 - Loss: 0.2615\n",
      "Epoch 400/500 - Loss: 0.2615\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2351\n",
      "Epoch 200/500 - Loss: 0.2351\n",
      "Epoch 300/500 - Loss: 0.2351\n",
      "Epoch 400/500 - Loss: 0.2351\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2398\n",
      "Epoch 200/500 - Loss: 0.2398\n",
      "Epoch 300/500 - Loss: 0.2398\n",
      "Epoch 400/500 - Loss: 0.2398\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2922\n",
      "Epoch 200/500 - Loss: 0.2922\n",
      "Epoch 300/500 - Loss: 0.2922\n",
      "Epoch 400/500 - Loss: 0.2922\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2590\n",
      "Epoch 200/500 - Loss: 0.2590\n",
      "Epoch 300/500 - Loss: 0.2590\n",
      "Epoch 400/500 - Loss: 0.2590\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1978\n",
      "Epoch 200/500 - Loss: 0.1978\n",
      "Epoch 300/500 - Loss: 0.1978\n",
      "Epoch 400/500 - Loss: 0.1978\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2547\n",
      "Epoch 200/500 - Loss: 0.2547\n",
      "Epoch 300/500 - Loss: 0.2547\n",
      "Epoch 400/500 - Loss: 0.2547\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2051\n",
      "Epoch 200/500 - Loss: 0.2051\n",
      "Epoch 300/500 - Loss: 0.2051\n",
      "Epoch 400/500 - Loss: 0.2051\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1851\n",
      "Epoch 200/500 - Loss: 0.1851\n",
      "Epoch 300/500 - Loss: 0.1851\n",
      "Epoch 400/500 - Loss: 0.1851\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2317\n",
      "Epoch 200/500 - Loss: 0.2317\n",
      "Epoch 300/500 - Loss: 0.2317\n",
      "Epoch 400/500 - Loss: 0.2317\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.1943\n",
      "Epoch 200/500 - Loss: 0.1943\n",
      "Epoch 300/500 - Loss: 0.1943\n",
      "Epoch 400/500 - Loss: 0.1943\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2286\n",
      "Epoch 200/500 - Loss: 0.2286\n",
      "Epoch 300/500 - Loss: 0.2286\n",
      "Epoch 400/500 - Loss: 0.2286\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2654\n",
      "Epoch 200/500 - Loss: 0.2654\n",
      "Epoch 300/500 - Loss: 0.2654\n",
      "Epoch 400/500 - Loss: 0.2654\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2034\n",
      "Epoch 200/500 - Loss: 0.2034\n",
      "Epoch 300/500 - Loss: 0.2034\n",
      "Epoch 400/500 - Loss: 0.2034\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2512\n",
      "Epoch 200/500 - Loss: 0.2512\n",
      "Epoch 300/500 - Loss: 0.2512\n",
      "Epoch 400/500 - Loss: 0.2512\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2512\n",
      "Epoch 200/500 - Loss: 0.2512\n",
      "Epoch 300/500 - Loss: 0.2512\n",
      "Epoch 400/500 - Loss: 0.2512\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2070\n",
      "Epoch 200/500 - Loss: 0.2070\n",
      "Epoch 300/500 - Loss: 0.2070\n",
      "Epoch 400/500 - Loss: 0.2070\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2484\n",
      "Epoch 200/500 - Loss: 0.2484\n",
      "Epoch 300/500 - Loss: 0.2484\n",
      "Epoch 400/500 - Loss: 0.2484\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2748\n",
      "Epoch 200/500 - Loss: 0.2748\n",
      "Epoch 300/500 - Loss: 0.2748\n",
      "Epoch 400/500 - Loss: 0.2748\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2228\n",
      "Epoch 200/500 - Loss: 0.2228\n",
      "Epoch 300/500 - Loss: 0.2228\n",
      "Epoch 400/500 - Loss: 0.2228\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2424\n",
      "Epoch 200/500 - Loss: 0.2424\n",
      "Epoch 300/500 - Loss: 0.2424\n",
      "Epoch 400/500 - Loss: 0.2424\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2939\n",
      "Epoch 200/500 - Loss: 0.2939\n",
      "Epoch 300/500 - Loss: 0.2939\n",
      "Epoch 400/500 - Loss: 0.2939\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2427\n",
      "Epoch 200/500 - Loss: 0.2427\n",
      "Epoch 300/500 - Loss: 0.2427\n",
      "Epoch 400/500 - Loss: 0.2427\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2334\n",
      "Epoch 200/500 - Loss: 0.2334\n",
      "Epoch 300/500 - Loss: 0.2334\n",
      "Epoch 400/500 - Loss: 0.2334\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2615\n",
      "Epoch 200/500 - Loss: 0.2615\n",
      "Epoch 300/500 - Loss: 0.2615\n",
      "Epoch 400/500 - Loss: 0.2615\n",
      "Epoch 0/500 - Loss: 6.8460\n",
      "Epoch 100/500 - Loss: 0.2351\n",
      "Epoch 200/500 - Loss: 0.2351\n",
      "Epoch 300/500 - Loss: 0.2351\n",
      "Epoch 400/500 - Loss: 0.2351\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3551\n",
      "Epoch 200/500 - Loss: 0.3551\n",
      "Epoch 300/500 - Loss: 0.3551\n",
      "Epoch 400/500 - Loss: 0.3551\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3556\n",
      "Epoch 200/500 - Loss: 0.3556\n",
      "Epoch 300/500 - Loss: 0.3556\n",
      "Epoch 400/500 - Loss: 0.3556\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3479\n",
      "Epoch 200/500 - Loss: 0.3479\n",
      "Epoch 300/500 - Loss: 0.3479\n",
      "Epoch 400/500 - Loss: 0.3479\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3533\n",
      "Epoch 200/500 - Loss: 0.3533\n",
      "Epoch 300/500 - Loss: 0.3533\n",
      "Epoch 400/500 - Loss: 0.3533\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3543\n",
      "Epoch 200/500 - Loss: 0.3543\n",
      "Epoch 300/500 - Loss: 0.3543\n",
      "Epoch 400/500 - Loss: 0.3543\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3422\n",
      "Epoch 200/500 - Loss: 0.3422\n",
      "Epoch 300/500 - Loss: 0.3422\n",
      "Epoch 400/500 - Loss: 0.3422\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3210\n",
      "Epoch 200/500 - Loss: 0.3210\n",
      "Epoch 300/500 - Loss: 0.3210\n",
      "Epoch 400/500 - Loss: 0.3210\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3556\n",
      "Epoch 200/500 - Loss: 0.3556\n",
      "Epoch 300/500 - Loss: 0.3556\n",
      "Epoch 400/500 - Loss: 0.3556\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3386\n",
      "Epoch 200/500 - Loss: 0.3386\n",
      "Epoch 300/500 - Loss: 0.3386\n",
      "Epoch 400/500 - Loss: 0.3386\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3304\n",
      "Epoch 200/500 - Loss: 0.3304\n",
      "Epoch 300/500 - Loss: 0.3304\n",
      "Epoch 400/500 - Loss: 0.3304\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3050\n",
      "Epoch 200/500 - Loss: 0.3050\n",
      "Epoch 300/500 - Loss: 0.3050\n",
      "Epoch 400/500 - Loss: 0.3050\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3050\n",
      "Epoch 200/500 - Loss: 0.3050\n",
      "Epoch 300/500 - Loss: 0.3050\n",
      "Epoch 400/500 - Loss: 0.3050\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3321\n",
      "Epoch 200/500 - Loss: 0.3321\n",
      "Epoch 300/500 - Loss: 0.3321\n",
      "Epoch 400/500 - Loss: 0.3321\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3384\n",
      "Epoch 200/500 - Loss: 0.3384\n",
      "Epoch 300/500 - Loss: 0.3384\n",
      "Epoch 400/500 - Loss: 0.3384\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3438\n",
      "Epoch 200/500 - Loss: 0.3438\n",
      "Epoch 300/500 - Loss: 0.3438\n",
      "Epoch 400/500 - Loss: 0.3438\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3153\n",
      "Epoch 200/500 - Loss: 0.3153\n",
      "Epoch 300/500 - Loss: 0.3153\n",
      "Epoch 400/500 - Loss: 0.3153\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3433\n",
      "Epoch 200/500 - Loss: 0.3433\n",
      "Epoch 300/500 - Loss: 0.3433\n",
      "Epoch 400/500 - Loss: 0.3433\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3551\n",
      "Epoch 200/500 - Loss: 0.3551\n",
      "Epoch 300/500 - Loss: 0.3551\n",
      "Epoch 400/500 - Loss: 0.3551\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3040\n",
      "Epoch 200/500 - Loss: 0.3040\n",
      "Epoch 300/500 - Loss: 0.3040\n",
      "Epoch 400/500 - Loss: 0.3040\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3192\n",
      "Epoch 200/500 - Loss: 0.3192\n",
      "Epoch 300/500 - Loss: 0.3192\n",
      "Epoch 400/500 - Loss: 0.3192\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3107\n",
      "Epoch 200/500 - Loss: 0.3107\n",
      "Epoch 300/500 - Loss: 0.3107\n",
      "Epoch 400/500 - Loss: 0.3107\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3272\n",
      "Epoch 200/500 - Loss: 0.3272\n",
      "Epoch 300/500 - Loss: 0.3272\n",
      "Epoch 400/500 - Loss: 0.3272\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.2968\n",
      "Epoch 200/500 - Loss: 0.2968\n",
      "Epoch 300/500 - Loss: 0.2968\n",
      "Epoch 400/500 - Loss: 0.2968\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.2968\n",
      "Epoch 200/500 - Loss: 0.2968\n",
      "Epoch 300/500 - Loss: 0.2968\n",
      "Epoch 400/500 - Loss: 0.2968\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3021\n",
      "Epoch 200/500 - Loss: 0.3021\n",
      "Epoch 300/500 - Loss: 0.3021\n",
      "Epoch 400/500 - Loss: 0.3021\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.2962\n",
      "Epoch 200/500 - Loss: 0.2962\n",
      "Epoch 300/500 - Loss: 0.2962\n",
      "Epoch 400/500 - Loss: 0.2962\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3352\n",
      "Epoch 200/500 - Loss: 0.3352\n",
      "Epoch 300/500 - Loss: 0.3352\n",
      "Epoch 400/500 - Loss: 0.3352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/loss.py:4: RuntimeWarning: overflow encountered in square\n",
      "  return np.mean((predictions - targets) ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3551\n",
      "Epoch 200/500 - Loss: 0.3551\n",
      "Epoch 300/500 - Loss: 0.3551\n",
      "Epoch 400/500 - Loss: 0.3551\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3556\n",
      "Epoch 200/500 - Loss: 0.3556\n",
      "Epoch 300/500 - Loss: 0.3556\n",
      "Epoch 400/500 - Loss: 0.3556\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3479\n",
      "Epoch 200/500 - Loss: 0.3479\n",
      "Epoch 300/500 - Loss: 0.3479\n",
      "Epoch 400/500 - Loss: 0.3479\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3533\n",
      "Epoch 200/500 - Loss: 0.3533\n",
      "Epoch 300/500 - Loss: 0.3533\n",
      "Epoch 400/500 - Loss: 0.3533\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3543\n",
      "Epoch 200/500 - Loss: 0.3543\n",
      "Epoch 300/500 - Loss: 0.3543\n",
      "Epoch 400/500 - Loss: 0.3543\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3422\n",
      "Epoch 200/500 - Loss: 0.3422\n",
      "Epoch 300/500 - Loss: 0.3422\n",
      "Epoch 400/500 - Loss: 0.3422\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3210\n",
      "Epoch 200/500 - Loss: 0.3210\n",
      "Epoch 300/500 - Loss: 0.3210\n",
      "Epoch 400/500 - Loss: 0.3210\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3556\n",
      "Epoch 200/500 - Loss: 0.3556\n",
      "Epoch 300/500 - Loss: 0.3556\n",
      "Epoch 400/500 - Loss: 0.3556\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3386\n",
      "Epoch 200/500 - Loss: 0.3386\n",
      "Epoch 300/500 - Loss: 0.3386\n",
      "Epoch 400/500 - Loss: 0.3386\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3304\n",
      "Epoch 200/500 - Loss: 0.3304\n",
      "Epoch 300/500 - Loss: 0.3304\n",
      "Epoch 400/500 - Loss: 0.3304\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3050\n",
      "Epoch 200/500 - Loss: 0.3050\n",
      "Epoch 300/500 - Loss: 0.3050\n",
      "Epoch 400/500 - Loss: 0.3050\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3050\n",
      "Epoch 200/500 - Loss: 0.3050\n",
      "Epoch 300/500 - Loss: 0.3050\n",
      "Epoch 400/500 - Loss: 0.3050\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3321\n",
      "Epoch 200/500 - Loss: 0.3321\n",
      "Epoch 300/500 - Loss: 0.3321\n",
      "Epoch 400/500 - Loss: 0.3321\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3384\n",
      "Epoch 200/500 - Loss: 0.3384\n",
      "Epoch 300/500 - Loss: 0.3384\n",
      "Epoch 400/500 - Loss: 0.3384\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3438\n",
      "Epoch 200/500 - Loss: 0.3438\n",
      "Epoch 300/500 - Loss: 0.3438\n",
      "Epoch 400/500 - Loss: 0.3438\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3153\n",
      "Epoch 200/500 - Loss: 0.3153\n",
      "Epoch 300/500 - Loss: 0.3153\n",
      "Epoch 400/500 - Loss: 0.3153\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3433\n",
      "Epoch 200/500 - Loss: 0.3433\n",
      "Epoch 300/500 - Loss: 0.3433\n",
      "Epoch 400/500 - Loss: 0.3433\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3551\n",
      "Epoch 200/500 - Loss: 0.3551\n",
      "Epoch 300/500 - Loss: 0.3551\n",
      "Epoch 400/500 - Loss: 0.3551\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3040\n",
      "Epoch 200/500 - Loss: 0.3040\n",
      "Epoch 300/500 - Loss: 0.3040\n",
      "Epoch 400/500 - Loss: 0.3040\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3192\n",
      "Epoch 200/500 - Loss: 0.3192\n",
      "Epoch 300/500 - Loss: 0.3192\n",
      "Epoch 400/500 - Loss: 0.3192\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3107\n",
      "Epoch 200/500 - Loss: 0.3107\n",
      "Epoch 300/500 - Loss: 0.3107\n",
      "Epoch 400/500 - Loss: 0.3107\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3272\n",
      "Epoch 200/500 - Loss: 0.3272\n",
      "Epoch 300/500 - Loss: 0.3272\n",
      "Epoch 400/500 - Loss: 0.3272\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.2968\n",
      "Epoch 200/500 - Loss: 0.2968\n",
      "Epoch 300/500 - Loss: 0.2968\n",
      "Epoch 400/500 - Loss: 0.2968\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.2968\n",
      "Epoch 200/500 - Loss: 0.2968\n",
      "Epoch 300/500 - Loss: 0.2968\n",
      "Epoch 400/500 - Loss: 0.2968\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3021\n",
      "Epoch 200/500 - Loss: 0.3021\n",
      "Epoch 300/500 - Loss: 0.3021\n",
      "Epoch 400/500 - Loss: 0.3021\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.2962\n",
      "Epoch 200/500 - Loss: 0.2962\n",
      "Epoch 300/500 - Loss: 0.2962\n",
      "Epoch 400/500 - Loss: 0.2962\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3352\n",
      "Epoch 200/500 - Loss: 0.3352\n",
      "Epoch 300/500 - Loss: 0.3352\n",
      "Epoch 400/500 - Loss: 0.3352\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3551\n",
      "Epoch 200/500 - Loss: 0.3551\n",
      "Epoch 300/500 - Loss: 0.3551\n",
      "Epoch 400/500 - Loss: 0.3551\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3556\n",
      "Epoch 200/500 - Loss: 0.3556\n",
      "Epoch 300/500 - Loss: 0.3556\n",
      "Epoch 400/500 - Loss: 0.3556\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3479\n",
      "Epoch 200/500 - Loss: 0.3479\n",
      "Epoch 300/500 - Loss: 0.3479\n",
      "Epoch 400/500 - Loss: 0.3479\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3533\n",
      "Epoch 200/500 - Loss: 0.3533\n",
      "Epoch 300/500 - Loss: 0.3533\n",
      "Epoch 400/500 - Loss: 0.3533\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3543\n",
      "Epoch 200/500 - Loss: 0.3543\n",
      "Epoch 300/500 - Loss: 0.3543\n",
      "Epoch 400/500 - Loss: 0.3543\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3422\n",
      "Epoch 200/500 - Loss: 0.3422\n",
      "Epoch 300/500 - Loss: 0.3422\n",
      "Epoch 400/500 - Loss: 0.3422\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3210\n",
      "Epoch 200/500 - Loss: 0.3210\n",
      "Epoch 300/500 - Loss: 0.3210\n",
      "Epoch 400/500 - Loss: 0.3210\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3556\n",
      "Epoch 200/500 - Loss: 0.3556\n",
      "Epoch 300/500 - Loss: 0.3556\n",
      "Epoch 400/500 - Loss: 0.3556\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3386\n",
      "Epoch 200/500 - Loss: 0.3386\n",
      "Epoch 300/500 - Loss: 0.3386\n",
      "Epoch 400/500 - Loss: 0.3386\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3304\n",
      "Epoch 200/500 - Loss: 0.3304\n",
      "Epoch 300/500 - Loss: 0.3304\n",
      "Epoch 400/500 - Loss: 0.3304\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3050\n",
      "Epoch 200/500 - Loss: 0.3050\n",
      "Epoch 300/500 - Loss: 0.3050\n",
      "Epoch 400/500 - Loss: 0.3050\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3050\n",
      "Epoch 200/500 - Loss: 0.3050\n",
      "Epoch 300/500 - Loss: 0.3050\n",
      "Epoch 400/500 - Loss: 0.3050\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3321\n",
      "Epoch 200/500 - Loss: 0.3321\n",
      "Epoch 300/500 - Loss: 0.3321\n",
      "Epoch 400/500 - Loss: 0.3321\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3384\n",
      "Epoch 200/500 - Loss: 0.3384\n",
      "Epoch 300/500 - Loss: 0.3384\n",
      "Epoch 400/500 - Loss: 0.3384\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3438\n",
      "Epoch 200/500 - Loss: 0.3438\n",
      "Epoch 300/500 - Loss: 0.3438\n",
      "Epoch 400/500 - Loss: 0.3438\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3153\n",
      "Epoch 200/500 - Loss: 0.3153\n",
      "Epoch 300/500 - Loss: 0.3153\n",
      "Epoch 400/500 - Loss: 0.3153\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3433\n",
      "Epoch 200/500 - Loss: 0.3433\n",
      "Epoch 300/500 - Loss: 0.3433\n",
      "Epoch 400/500 - Loss: 0.3433\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3551\n",
      "Epoch 200/500 - Loss: 0.3551\n",
      "Epoch 300/500 - Loss: 0.3551\n",
      "Epoch 400/500 - Loss: 0.3551\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3040\n",
      "Epoch 200/500 - Loss: 0.3040\n",
      "Epoch 300/500 - Loss: 0.3040\n",
      "Epoch 400/500 - Loss: 0.3040\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3192\n",
      "Epoch 200/500 - Loss: 0.3192\n",
      "Epoch 300/500 - Loss: 0.3192\n",
      "Epoch 400/500 - Loss: 0.3192\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3107\n",
      "Epoch 200/500 - Loss: 0.3107\n",
      "Epoch 300/500 - Loss: 0.3107\n",
      "Epoch 400/500 - Loss: 0.3107\n",
      "Epoch 0/500 - Loss: 20.7855\n",
      "Epoch 100/500 - Loss: 0.3272\n",
      "Epoch 200/500 - Loss: 0.3272\n",
      "Epoch 300/500 - Loss: 0.3272\n",
      "Epoch 400/500 - Loss: 0.3272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main copy.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m informants_space \u001b[39m=\u001b[39m [\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m activations \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m best_params, best_accuracy \u001b[39m=\u001b[39m grid_search(architecture_space, c1_space, c2_space, c3_space, informants_space)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Parameters:\u001b[39m\u001b[39m\"\u001b[39m, best_params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Accuracy:\u001b[39m\u001b[39m\"\u001b[39m, best_accuracy)\n",
      "\u001b[1;32m/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main copy.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pso_parameters \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mc1\u001b[39m\u001b[39m'\u001b[39m: c1,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mc2\u001b[39m\u001b[39m'\u001b[39m: c2,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mc3\u001b[39m\u001b[39m'\u001b[39m: c3,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minformants_per_particle\u001b[39m\u001b[39m'\u001b[39m: informants_per_particle,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Запускаем оптимизацию\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m gbest_params \u001b[39m=\u001b[39m optimize(network, X_train_scaled, y_train, dimensions, pso_parameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Тестируем сеть\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Biologically/CW/main%20copy.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m output \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mforward(X_test_scaled)\n",
      "File \u001b[0;32m~/Desktop/GitHub_Repositories/HW_University/Biologically/CW/pso_gridsearchcv.py:59\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(network, data, target, dimensions, pso_params, loss_function)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m particles:\n\u001b[1;32m     57\u001b[0m     \u001b[39m# Evaluate fitness\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     network\u001b[39m.\u001b[39mset_weights(p\u001b[39m.\u001b[39mparams)\n\u001b[0;32m---> 59\u001b[0m     output \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mforward(data)\n\u001b[1;32m     60\u001b[0m     fitness \u001b[39m=\u001b[39m loss_function(output, target)\n\u001b[1;32m     62\u001b[0m     \u001b[39m# Update personal best\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub_Repositories/HW_University/Biologically/CW/network.py:15\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     13\u001b[0m output \u001b[39m=\u001b[39m input_data\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 15\u001b[0m     output \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(output)\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Desktop/GitHub_Repositories/HW_University/Biologically/CW/layer.py:26\u001b[0m, in \u001b[0;36mNeuralLayer.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_data):\n\u001b[1;32m     25\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_data \u001b[39m=\u001b[39m input_data\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function(np\u001b[39m.\u001b[39;49mdot(input_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases)\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from numpy import mean\n",
    "\n",
    "def grid_search(architecture_space, c1_space, c2_space, c3_space, informants_space):\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Итерация по всем комбинациям параметров\n",
    "    for architecture, c1, c2, c3, informants_per_particle in product(architecture_space, c1_space, c2_space, c3_space, informants_space):\n",
    "        # Строим и обучаем сеть\n",
    "        network = build_network(architecture, activations)\n",
    "        dimensions = sum([layer.weights.size + layer.biases.size for layer in network.layers])\n",
    "\n",
    "        # Обновляем параметры PSO\n",
    "        pso_parameters = {\n",
    "            'c1': c1,\n",
    "            'c2': c2,\n",
    "            'c3': c3,\n",
    "            'informants_per_particle': informants_per_particle,\n",
    "        }\n",
    "\n",
    "        # Запускаем оптимизацию\n",
    "        gbest_params = optimize(network, X_train_scaled, y_train, dimensions, pso_parameters)\n",
    "\n",
    "        # Тестируем сеть\n",
    "        output = network.forward(X_test_scaled)\n",
    "        predictions = (output > 0.5).astype(int)\n",
    "        accuracy = (predictions == y_test).mean()\n",
    "\n",
    "        # Обновляем лучшие параметры, если нашли лучше\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {\n",
    "                'architecture': architecture,\n",
    "                'c1': c1,\n",
    "                'c2': c2,\n",
    "                'c3': c3,\n",
    "                'informants_per_particle': informants_per_particle,\n",
    "            }\n",
    "    \n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Пример использования:\n",
    "architecture_space = [[4, 8, 1], [4, 10, 1], [4, 8, 8, 1]]\n",
    "c1_space = [1.5, 2.0, 2.5]\n",
    "c2_space = [1.5, 2.0, 2.5]\n",
    "c3_space = [0.3, 0.5, 0.7]\n",
    "informants_space = [3, 5, 7]\n",
    "\n",
    "activations = ['relu', 'relu', 'sigmoid']\n",
    "\n",
    "best_params, best_accuracy = grid_search(architecture_space, c1_space, c2_space, c3_space, informants_space)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_space = [[4, 8, 1], [4, 10, 1], [4, 8, 8, 1]]\n",
    "c1_space = [1.5, 2.0, 2.5]\n",
    "c2_space = [1.5, 2.0, 2.5]\n",
    "c3_space = [0.3, 0.5, 0.7]\n",
    "informants_space = [3, 5, 7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (mainvenv)",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
