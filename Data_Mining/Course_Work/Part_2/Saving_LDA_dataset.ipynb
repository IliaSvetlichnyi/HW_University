{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_train_all.csv')\n",
    "y = pd.read_csv('/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_train_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9690, 2304)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to range [0, 1]\n",
    "x_normalized = X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_normalized, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ilya/mainvenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components cannot be larger than min(n_features, n_classes - 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Saving_LDA_dataset.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Saving_LDA_dataset.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_components \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m15\u001b[39m):  \u001b[39m# For example, from 10 to 190, in steps of 10\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Saving_LDA_dataset.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     lda \u001b[39m=\u001b[39m LDA(n_components\u001b[39m=\u001b[39mn_components)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Saving_LDA_dataset.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     X_train_lda \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39;49mfit_transform(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Saving_LDA_dataset.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     X_test_lda \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Saving_LDA_dataset.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# Apply Gaussian Naive Bayes\u001b[39;00m\n",
      "File \u001b[0;32m~/mainvenv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/mainvenv/lib/python3.10/site-packages/sklearn/base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/mainvenv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:608\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39m>\u001b[39m max_components:\n\u001b[0;32m--> 608\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    609\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mn_components cannot be larger than min(n_features, n_classes - 1).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_components \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msvd\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: n_components cannot be larger than min(n_features, n_classes - 1)."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Dictionary to store the F1-score for each number of PCA components\n",
    "f1_scores = {}\n",
    "\n",
    "# Iterate over a range of PCA components\n",
    "for n_components in range(1, 15):  # For example, from 10 to 190, in steps of 10\n",
    "    lda = LDA(n_components=n_components)\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    # Apply Gaussian Naive Bayes\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train_lda, y_train.values.ravel())\n",
    "    y_pred_lda = gnb.predict(X_test_lda)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_test, y_pred_lda, average='weighted')\n",
    "    f1_scores[n_components] = f1\n",
    "\n",
    "# Find the number of PCA components that gives the maximum F1-score\n",
    "best_n_components = max(f1_scores, key=f1_scores.get)\n",
    "best_f1_score = f1_scores[best_n_components]\n",
    "\n",
    "print(f\"The best number of LDA components is {best_n_components} with an F1-score of {best_f1_score:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=2)  # n_components is the number of dimensions you want to project down to\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "# Now X_train_lda and X_test_lda can be used for further analysis or classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda_classifier = LDA()\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lda_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9690, 53)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1030</th>\n",
       "      <th>1121</th>\n",
       "      <th>1122</th>\n",
       "      <th>1074</th>\n",
       "      <th>1264</th>\n",
       "      <th>982</th>\n",
       "      <th>1031</th>\n",
       "      <th>1078</th>\n",
       "      <th>1169</th>\n",
       "      <th>1170</th>\n",
       "      <th>...</th>\n",
       "      <th>1271</th>\n",
       "      <th>1075</th>\n",
       "      <th>1218</th>\n",
       "      <th>1320</th>\n",
       "      <th>1167</th>\n",
       "      <th>1368</th>\n",
       "      <th>1509</th>\n",
       "      <th>1032</th>\n",
       "      <th>1221</th>\n",
       "      <th>1172</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.737255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.850980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.756863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.752941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1030      1121      1122      1074      1264       982      1031  \\\n",
       "0  0.607843  0.772549  0.749020  0.639216  0.917647  0.749020  0.705882   \n",
       "1  0.517647  0.796078  0.796078  0.764706  0.760784  0.552941  0.533333   \n",
       "2  0.529412  0.811765  0.772549  0.701961  0.890196  0.556863  0.470588   \n",
       "3  0.498039  0.854902  0.854902  0.811765  0.882353  0.533333  0.525490   \n",
       "4  0.592157  0.666667  0.603922  0.588235  0.878431  0.831373  0.745098   \n",
       "\n",
       "       1078      1169      1170  ...      1271      1075      1218      1320  \\\n",
       "0  0.509804  0.878431  0.843137  ...  0.733333  0.588235  0.874510  0.733333   \n",
       "1  0.607843  0.858824  0.854902  ...  0.690196  0.694118  0.898039  0.784314   \n",
       "2  0.650980  0.878431  0.850980  ...  0.698039  0.717647  0.874510  0.772549   \n",
       "3  0.478431  0.890196  0.854902  ...  0.788235  0.835294  0.811765  0.682353   \n",
       "4  0.525490  0.666667  0.631373  ...  0.478431  0.541176  0.764706  0.764706   \n",
       "\n",
       "       1167      1368      1509      1032      1221      1172  \n",
       "0  0.827451  0.733333  0.572549  0.721569  0.627451  0.737255  \n",
       "1  0.478431  0.698039  0.639216  0.549020  0.654902  0.850980  \n",
       "2  0.741176  0.713725  0.701961  0.486275  0.533333  0.756863  \n",
       "3  0.792157  0.592157  0.835294  0.537255  0.509804  0.627451  \n",
       "4  0.729412  0.800000  0.439216  0.862745  0.764706  0.752941  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We tried different number of features and \"150\" is the most efficient number of features\n",
    "X_rf = x_normalized[indices_rf[:53].astype(str)]\n",
    "print(X_rf.shape)\n",
    "X_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.83      0.35        42\n",
      "           1       0.73      0.51      0.60       444\n",
      "           2       0.76      0.34      0.47       450\n",
      "           3       0.31      0.60      0.41       282\n",
      "           4       0.98      0.16      0.27       396\n",
      "           5       0.57      0.19      0.29        42\n",
      "           6       0.24      0.64      0.34        72\n",
      "           7       0.50      0.35      0.41        48\n",
      "           8       0.58      0.48      0.53       108\n",
      "           9       0.13      0.78      0.22        54\n",
      "\n",
      "    accuracy                           0.42      1938\n",
      "   macro avg       0.50      0.49      0.39      1938\n",
      "weighted avg       0.66      0.42      0.43      1938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "X_train_rf, X_tes_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Applying Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_rf, y_train_rf.values.ravel())\n",
    "y_pred_rf = gnb.predict(X_tes_rf)\n",
    "\n",
    "# Calculating the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "class_report = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(accuracy.round(3))\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf = pd.DataFrame(X_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rf = pd.DataFrame(X_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf.to_csv(\"X_train_rf.csv\", sep=',', index=False)\n",
    "X_test_rf.to_csv(\"X_test_rf.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (mainvenv)",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
