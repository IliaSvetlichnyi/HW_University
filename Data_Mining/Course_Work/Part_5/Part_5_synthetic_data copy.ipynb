{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 12:55:45.549810: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-29 12:55:45.550317: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-11-29 12:55:45.761133: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 12:55:45.998339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 4s 13ms/step - loss: 1.4260 - accuracy: 0.5288\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 4s 12ms/step - loss: 0.7805 - accuracy: 0.7706\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.6330 - accuracy: 0.8187\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.5475 - accuracy: 0.8424\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 4s 14ms/step - loss: 0.4895 - accuracy: 0.8614\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.4358 - accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 3s 12ms/step - loss: 0.3928 - accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.3598 - accuracy: 0.8958\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 4s 14ms/step - loss: 0.3317 - accuracy: 0.9041\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.3160 - accuracy: 0.9103\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 53), found shape=(None, 509)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data copy.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data%20copy.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_resampled, y_train_encoded,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data%20copy.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m           epochs\u001b[39m=\u001b[39mnum_epochs, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data%20copy.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data%20copy.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data%20copy.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m predicted_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/Part_5/Part_5_synthetic_data%20copy.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m y_test_labels \u001b[39m=\u001b[39m y_test[\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Ensure '0' is the correct label column\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4w/m9s63hx144n554zlymqn4x7h0000gn/T/__autograph_generated_filekuc30243.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ilya/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 53), found shape=(None, 509)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your dataset\n",
    "X_test = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/datasets/X_test_rf.csv')\n",
    "X_train = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/datasets/X_train_rf.csv')\n",
    "y_train = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/datasets/y_train.csv')\n",
    "y_test = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/Course_Work/datasets/y_test.csv')\n",
    "\n",
    "# Apply SMOTE for class imbalance\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(\n",
    "    X_train, y_train['0'])  # Ensure '0' is the correct label column\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "num_classes = 10  # Adjust based on the number of classes\n",
    "y_train_encoded = to_categorical(y_train_resampled, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test['0'], num_classes=num_classes)\n",
    "\n",
    "# Define a Sequential model for 1D input\n",
    "model = Sequential()\n",
    "# '53' should match the number of features\n",
    "model.add(Dense(256, activation='relu', input_shape=(53,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "model.fit(X_train_resampled, y_train_encoded,\n",
    "          epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "y_test_labels = y_test['0']  # Ensure '0' is the correct label column\n",
    "accuracy = np.mean(predicted_classes == y_test_labels)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_train_all.csv')\n",
    "\n",
    "X_test = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_test_all.csv')\n",
    "\n",
    "y_train = pd.read_csv(\n",
    "    \"/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_train_all.csv\")\n",
    "\n",
    "y_test = pd.read_csv(\n",
    "    \"/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_test_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "2    2250\n",
       "1    2220\n",
       "4    1980\n",
       "3    1410\n",
       "8     540\n",
       "6     360\n",
       "9     270\n",
       "7     240\n",
       "0     210\n",
       "5     210\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0    2250\n",
      "1    2250\n",
      "2    2250\n",
      "3    2250\n",
      "4    2250\n",
      "5    2250\n",
      "6    2250\n",
      "7    2250\n",
      "8    2250\n",
      "9    2250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create an instance of SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(y_train_resampled['0'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 48\n",
    "image_width = 48\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train to match the expected input shape\n",
    "X_train_reshaped = np.reshape(\n",
    "    X_train, (X_train.shape[0], image_height, image_width, num_channels))\n",
    "\n",
    "# Reshape X_test to match the expected input shape\n",
    "X_test_reshaped = np.reshape(\n",
    "    X_test, (X_test.shape[0], image_height, image_width, num_channels))\n",
    "\n",
    "# Convert y_train to one-hot encoded format\n",
    "y_train_encoded = to_categorical(y_train, num_classes)\n",
    "\n",
    "# Convert y_test to one-hot encoded format\n",
    "y_test_encoded = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 12:58:20.090181: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-23 12:58:20.090325: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 12:58:21.031675: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-11-23 12:58:21.379485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 9s 31ms/step - loss: 2.9428 - accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.2690 - accuracy: 0.5429\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5096 - accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2588 - accuracy: 0.9305\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1774 - accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1398 - accuracy: 0.9633\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0887 - accuracy: 0.9741\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1016 - accuracy: 0.9720\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0684 - accuracy: 0.9802\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0786 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16493f880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# 98% accuracy on the test set\n",
    "\n",
    "# Define the CNN model with dropout layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(image_height, image_width, num_channels)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Add dropout layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Add dropout layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Add dropout layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add dropout layer\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add dropout layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train_encoded, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/303 [..............................] - ETA: 4s - loss: 0.0377 - accuracy: 0.9812      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 12:59:04.569758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 4s 11ms/step - loss: 0.0098 - accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009827748872339725, 0.9979360103607178]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_reshaped, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0437 - accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04366050660610199, 0.9860841631889343]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we got 98.6% accuracy on the test set due to producing synthetic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
