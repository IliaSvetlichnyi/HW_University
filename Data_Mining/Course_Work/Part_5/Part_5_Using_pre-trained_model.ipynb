{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we will use a pre-trained model to classify images, to see if it's better than building your own model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will use MobileNet which is a deep learning model architecture that is designed for efficient and lightweight image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 23:47:39.893710: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-29 23:47:39.893839: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 23:47:50.930161: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-11-29 23:47:52.198254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 26s 128ms/step - loss: 0.4458 - accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.1212 - accuracy: 0.9763\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.0264 - accuracy: 0.9918\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 14s 92ms/step - loss: 0.0152 - accuracy: 0.9962\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.0294 - accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.0154 - accuracy: 0.9961\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 17s 113ms/step - loss: 0.0074 - accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 13s 85ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 12s 78ms/step - loss: 0.0347 - accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 12s 77ms/step - loss: 0.0497 - accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 23:50:33.836176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 2s 15ms/step\n",
      "Accuracy: 0.9948220064724919\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from skimage.transform import resize\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Load the MobileNet model pre-trained on ImageNet data\n",
    "base_model = MobileNet(\n",
    "    weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # Flatten the output layer to one dimension\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Function to preprocess the dataset\n",
    "def preprocess_data(X, target_size):\n",
    "    # Reshape and resize the data\n",
    "    X_reshaped = np.reshape(X.values, (-1, 48, 48))\n",
    "    X_resized = np.array([resize(img, (target_size, target_size))\n",
    "                         for img in X_reshaped])\n",
    "    X_rgb = np.repeat(X_resized[..., np.newaxis], 3, axis=3)\n",
    "\n",
    "    # Preprocess the input for MobileNet\n",
    "    X_preprocessed = preprocess_input(X_rgb)\n",
    "    return X_preprocessed\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "X_train = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_train_all.csv')\n",
    "\n",
    "X_test = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_test_all.csv')\n",
    "\n",
    "y_train = pd.read_csv(\n",
    "    \"/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_train_all.csv\")[\"0\"]\n",
    "\n",
    "y_test = pd.read_csv(\n",
    "    \"/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_test_all.csv\")[\"0\"]\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_preprocessed = preprocess_data(X_train, 96)\n",
    "X_test_preprocessed = preprocess_data(X_test, 96)\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_preprocessed, y_train_encoded, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_preprocessed)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "accuracy = np.mean(predicted_classes == y_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we got 99.5% accuracy using pretrained model MobileNet which is the highest score which we have ever got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the same model, but with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 00:01:46.962649: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 15s 83ms/step - loss: 0.9143 - accuracy: 0.7939\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.1469 - accuracy: 0.9517\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 0.1543 - accuracy: 0.9575\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.0900 - accuracy: 0.9702\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.0966 - accuracy: 0.9721\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.0640 - accuracy: 0.9789\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.0670 - accuracy: 0.9815\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.0511 - accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 0.0487 - accuracy: 0.9849\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 0.0442 - accuracy: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 00:03:47.688235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 2s 13ms/step\n",
      "Accuracy: 0.9715210355987055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from skimage.transform import resize\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Augmentation setup\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      # Rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,  # Shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2, # Shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,        # Shear images by up to 20 degrees\n",
    "    zoom_range=0.2,         # Zoom in on images by up to 20%\n",
    "    horizontal_flip=True,   # Allow horizontal flipping\n",
    "    fill_mode='nearest'     # Fill in newly created pixels\n",
    ")\n",
    "\n",
    "# Load the MobileNet model pre-trained on ImageNet data\n",
    "base_model = MobileNet(\n",
    "    weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # Flatten the output layer to one dimension\n",
    "\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Function to preprocess the dataset\n",
    "\n",
    "\n",
    "def preprocess_data(X, target_size):\n",
    "    # Reshape and resize the data\n",
    "    X_reshaped = np.reshape(X.values, (-1, 48, 48))\n",
    "    X_resized = np.array([resize(img, (target_size, target_size))\n",
    "                         for img in X_reshaped])\n",
    "    X_rgb = np.repeat(X_resized[..., np.newaxis], 3, axis=3)\n",
    "\n",
    "    # Preprocess the input for MobileNet\n",
    "    X_preprocessed = preprocess_input(X_rgb)\n",
    "    return X_preprocessed\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "X_train = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_train_all.csv')\n",
    "\n",
    "X_test = pd.read_csv(\n",
    "    '/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/x_test_all.csv')\n",
    "\n",
    "y_train = pd.read_csv(\n",
    "    \"/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_train_all.csv\")[\"0\"]\n",
    "\n",
    "y_test = pd.read_csv(\n",
    "    \"/Users/ilya/Desktop/Course_work_Data_mining/CompleteDataSet/y_test_all.csv\")[\"0\"]\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_preprocessed = preprocess_data(X_train, 96)\n",
    "X_test_preprocessed = preprocess_data(X_test, 96)\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Fit the model with data augmentation\n",
    "model.fit(datagen.flow(X_train_preprocessed, y_train_encoded, batch_size=64),\n",
    "          steps_per_epoch=len(X_train_preprocessed) / 64, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_preprocessed)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "accuracy = np.mean(predicted_classes == y_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using synthetic data for pre-trained model just makes it worse. We got only 97.1 % accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
